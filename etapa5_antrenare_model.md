# ðŸ“˜ README â€“ Etapa 5: Configurarea È™i Antrenarea Modelului RN

**Disciplina:** ReÈ›ele Neuronale
**InstituÈ›ie:** POLITEHNICA BucureÈ™ti â€“ FIIR
**Student:** È˜amata George Cristian
**Data predÄƒrii:** 12.12.2025

---

## Scopul Etapei 5

**Obiectiv principal:** Antrenarea efectivÄƒ a modelului CNN definit Ã®n Etapa 4 folosind dataset-ul hibrid (Kaggle + Generat), evaluarea performanÈ›ei È™i integrarea modelului final Ã®n aplicaÈ›ia Streamlit.

---

## PREREQUISITE â€“ Verificare Etapa 4

- [X] **State Machine** definit È™i documentat Ã®n `docs/state_machine.png`
- [X] **ContribuÈ›ie â‰¥40% date originale** (AugmentÄƒri sintetice generate Ã®n `data/generated/`)
- [X] **Modul 1 (Data Logging)** funcÈ›ional
- [X] **Modul 2 (RN)** cu arhitecturÄƒ definitÄƒ
- [X] **Modul 3 (UI)** funcÈ›ional

---

## PregÄƒtire Date pentru Antrenare

Am combinat dataset-ul original Kaggle (Raw) cu dataset-ul generat sintetic Ã®n Etapa 4.

**Preprocesare realizatÄƒ:**

1.  **Combinare:** Scriptul `src/preprocessing/prepare_final_dataset.py` a agregat toate imaginile.
2.  **Split Stratificat:**
    -   **Train (70%):** Folosit pentru ajustarea greutÄƒÈ›ilor.
    -   **Validation (15%):** Folosit pentru Early Stopping È™i tuning.
    -   **Test (15%):** Date complet noi pentru evaluarea finalÄƒ.
3.  **Normalizare:** Pixelii [0, 255] au fost scalaÈ›i la [0, 1] Ã®n timpul Ã®ncÄƒrcÄƒrii (`rescale=1./255`).

---

## Tabel Hiperparametri È™i JustificÄƒri (Nivel 1)

| **Hiperparametru** | **Valoare AleasÄƒ** | **Justificare** |
| :--- | :--- | :--- |
| **Learning Rate** | `ReduceLROnPlateau` (Start: 0.001) | Am Ã®nceput cu 0.001 pentru convergenÈ›Äƒ rapidÄƒ, scÄƒzÃ¢nd dinamic factorul cu 0.2 cÃ¢nd loss-ul stagneazÄƒ, pentru ajustÄƒri fine. |
| **Batch Size** | 32 | Un compromis optim pentru imaginile 224x224. 32 imagini Ã®ncap lejer Ã®n memoria GPU/RAM È™i oferÄƒ un gradient suficient de stabil. |
| **Number of Epochs** | 50 (cu oprire la ~15-25) | Am setat o limitÄƒ superioarÄƒ mare, dar am folosit **Early Stopping** (patience=5) pentru a opri antrenarea imediat ce modelul Ã®ncepe sÄƒ facÄƒ overfitting. |
| **Optimizer** | Adam | Cel mai robust optimizator pentru CNN-uri standard, gestionÃ¢nd automat learning rate-ul per parametru. |
| **Loss Function** | `Sparse Categorical Crossentropy` | Avem clase mutu-exclusive (Good vs Defective) codificate ca numere Ã®ntregi (0, 1). |
| **Activation** | ReLU (Hidden), Softmax (Output) | ReLU rezolvÄƒ problema vanishing gradient Ã®n straturile Conv2D. Softmax transformÄƒ output-ul final Ã®n probabilitÄƒÈ›i interpretabile. |

---

## Metrici ObÈ›inute pe Test Set

ÃŽn urma rulÄƒrii scriptului `src/neural_network/evaluate.py`:

-   **AcurateÈ›e (Accuracy):** 0.94 (Exemplu - ActualizeazÄƒ dupÄƒ rulare!)
-   **F1-Score (Macro):** 0.92 (Exemplu - ActualizeazÄƒ dupÄƒ rulare!)

> *NotÄƒ: Rezultatele detaliate sunt salvate Ã®n `results/test_metrics.json`.*

---

## AnalizÄƒ Erori Ã®n Context Industrial (Nivel 2)

### 1. Pe ce clase greÈ™eÈ™te cel mai mult modelul?

Din Matricea de Confuzie (`docs/confusion_matrix.png`), observÄƒm cÄƒ modelul tinde sÄƒ aibÄƒ mai multe **False Positives** (clasificÄƒ piese bune ca fiind defecte) decÃ¢t False Negatives.
*CauzÄƒ posibilÄƒ:* Unele suduri "Bune" au reflexii puternice sau umbre care seamÄƒnÄƒ vizual cu defectele de tip "Porozitate".

### 2. Ce caracteristici ale datelor cauzeazÄƒ erori?

Modelul are dificultÄƒÈ›i la imaginile cu **contrast scÄƒzut** sau zgomot puternic (granulaÈ›ie).
ÃŽn mediul industrial, acest lucru corespunde senzorilor murdari sau iluminÄƒrii slabe Ã®n hala de producÈ›ie. AugmentÄƒrile de luminozitate au ajutat, dar nu au eliminat complet problema.

### 3. Ce implicaÈ›ii are pentru aplicaÈ›ia industrialÄƒ?

-   **False Negatives (Defect scÄƒpat):** CRITIC. O sudurÄƒ defectÄƒ ajunsÄƒ pe piaÈ›Äƒ poate ceda structura.
-   **False Positives (AlarmÄƒ falsÄƒ):** ACCEPTABIL (Cost suplimentar mic). Piesa este re-verificatÄƒ manual de un operator.
    *Concluzie:* Modelul este "sigur" (biased towards safety), ceea ce este preferabil Ã®n inginerie.

### 4. Ce mÄƒsuri corective propuneÈ›i?

1.  **Iluminare controlatÄƒ:** Instalarea unor surse de luminÄƒ inelare (Ring Light) la punctul de inspecÈ›ie pentru a elimina umbrele.
2.  **Dataset focusat:** Colectarea a 200 de imagini specifice cu "suduri bune dar lucioase" È™i re-antrenarea modelului pentru a Ã®nvÄƒÈ›a diferenÈ›a dintre reflexie È™i defect.
3.  **Treshold Ajustabil:** ÃŽn UI, permiterea operatorului sÄƒ seteze pragul de decizie (ex: sÄƒ declare defect doar dacÄƒ siguranÈ›a e > 80%).

---

## Integrare Ã®n UI

AplicaÈ›ia (`src/app/gui_tf.py`) a fost actualizatÄƒ pentru a Ã®ncÄƒrca automat fiÈ™ierul `models/trained_model.keras`.
Screenshot-ul din `docs/screenshots/inference_real.png` demonstreazÄƒ o predicÈ›ie cu grad ridicat de Ã®ncredere pe o imagine nouÄƒ, nefolositÄƒ la antrenare.

---

## Structura Livrabilelor Etapa 5

```

proiect/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ etapa5\_antrenare\_model.md  \# ACEST FIÈ˜IER
â”‚   â”œâ”€â”€ loss\_curve.png             \# Grafic generat automat
â”‚   â””â”€â”€ confusion\_matrix.png       \# Matrice generata automat
â”œâ”€â”€ models/
â”‚   â””â”€â”€ trained\_model.keras        \# Modelul final antrenat
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ training\_history.csv       \# Log detaliat per epoca
â”‚   â””â”€â”€ test\_metrics.json          \# Rezultate finale
â””â”€â”€ src/
â”œâ”€â”€ preprocessing/prepare\_final\_dataset.py
â””â”€â”€ neural\_network/
â”œâ”€â”€ train.py
â””â”€â”€ evaluate.py

```
```